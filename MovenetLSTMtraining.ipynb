{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56e3GrCKgoeJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable GPU growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Flatten, Dropout, Conv1D, MaxPooling1D, Bidirectional\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#some preprocess functions:\n",
        "def reshape_data(input_data):\n",
        "  #take first 12 one's\n",
        "    for i in range(0, len(input_data)):\n",
        "      input_data[i] = input_data[i][:24]\n",
        "\n",
        "\n",
        "    #remove the probability of each keypoint\n",
        "    euclidean_data_list = []\n",
        "    for video_data in input_data:\n",
        "        euclidean_data = video_data[:, :, :2]\n",
        "        euclidean_data_list.append(euclidean_data)\n",
        "\n",
        "    input_data = euclidean_data_list\n",
        "    indexes_to_delete = [1, 2, 3, 4, 13, 14, 15, 16]\n",
        "    for i, video_data in enumerate(input_data):\n",
        "        video_data = np.delete(video_data, indexes_to_delete, axis=1)\n",
        "        input_data[i] = video_data\n",
        "\n",
        "    #reshape to (batch numbers, 24,  34)\n",
        "    max_frames = max(len(video) for video in input_data)\n",
        "    reshaped_output = np.zeros((len(input_data), max_frames, 18))\n",
        "    print(len(input_data))\n",
        "    for i, video in enumerate(input_data):\n",
        "        reshaped_video = video.reshape(video.shape[0], -1)\n",
        "        reshaped_output[i, :len(video)] = reshaped_video\n",
        "    normalized_data = (reshaped_output - np.mean(reshaped_output)) / np.std(reshaped_output)\n",
        "    return reshaped_output\n",
        "\n",
        "def preprocess_datasets(dataset_vars, split_amount):\n",
        "    reshaped_data = []\n",
        "    numerical_labels = []\n",
        "\n",
        "    for var_names in dataset_vars:\n",
        "        # Load dataset\n",
        "        pose_keypoints_list = var_names[0]\n",
        "        labels_list = var_names[1]\n",
        "\n",
        "        # Reshape data\n",
        "        reshaped_data.append(reshape_data(pose_keypoints_list))\n",
        "\n",
        "        # Convert labels to numerical values\n",
        "        numerical_labels.append(np.array([label_mapping[label] for label in labels_list]))\n",
        "\n",
        "    # Concatenate all the data\n",
        "    X = tf.convert_to_tensor(np.concatenate(reshaped_data, axis=0), dtype=tf.float32)\n",
        "    y = tf.keras.utils.to_categorical(np.concatenate(numerical_labels))\n",
        "\n",
        "    # Shuffle the data\n",
        "    indices = np.random.permutation(len(X))\n",
        "    indices_tensor = tf.convert_to_tensor(indices, dtype=tf.int32)\n",
        "    X = tf.gather(X, indices_tensor)\n",
        "    y = tf.gather(y, indices_tensor)\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    train_size = int(split_amount * len(X))\n",
        "    val_size = len(X) - train_size\n",
        "\n",
        "    X_train, X_val = X[:train_size], X[train_size:]\n",
        "    y_train, y_val = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "\n",
        "def plot_points_with_slider(points):\n",
        "    # Create the initial scatter plot\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add traces for each time step\n",
        "    for t in range(24):\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=points[t, :, 0],\n",
        "            y=points[t, :, 1],\n",
        "            mode='markers',\n",
        "            name=f'Time Step {t}',\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                color='blue'\n",
        "            )\n",
        "        ))\n",
        "\n",
        "    # Update layout settings\n",
        "    fig.update_layout(\n",
        "        title='Points Over Time',\n",
        "        xaxis=dict(range=[0, 1]),\n",
        "        yaxis=dict(range=[0, 1]),\n",
        "        hovermode='closest',\n",
        "        sliders=[{\n",
        "            'currentvalue': {'prefix': 'Time Step: '},\n",
        "            'steps': [{'label': str(t), 'method': 'update', 'args': [{'visible': [t == i for i in range(24)]}]} for t in range(24)]\n",
        "        }]\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "TKDSVRBBgyr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load test data\n",
        "pose_keypoints_test = np.load('/content/drive/MyDrive/ModelFiles/padding/pose_keypoints_list_thunder_nao2_pad.npy', allow_pickle=True)\n",
        "labels_list_test = np.load('/content/drive/MyDrive/ModelFiles/padding/labels_list_thunder_nao2_pad.npy', allow_pickle=True)\n",
        "\n",
        "for i, item in enumerate(labels_list_test):\n",
        "    if item == 'corner-kick-red':\n",
        "        labels_list_test[i] = 'Corner-kick Red'\n",
        "    elif item == 'corner-kick-blue':\n",
        "        labels_list_test[i] = 'Corner-kick Blue'\n",
        "    elif item == 'goal-red':\n",
        "        labels_list_test[i] = 'Goal Red'\n",
        "    elif item == 'goal-blue':\n",
        "        labels_list_test[i] = 'Goal Blue'\n",
        "    elif item == 'goal-kick-red':\n",
        "        labels_list_test[i] = 'Goal-kick Red'\n",
        "    elif item == 'goal-kick-blue':\n",
        "        labels_list_test[i] = 'Goal-kick Blue'\n",
        "    elif item == 'kick-in-red':\n",
        "        labels_list_test[i] = 'Kick-in Red'\n",
        "    elif item == 'kick-in-blue':\n",
        "        labels_list_test[i] = 'Kick-in Blue'\n",
        "    elif item == 'player-exchange-red':\n",
        "        labels_list_test[i] = 'Player exchange Red'\n",
        "    elif item == 'player-exchange-blue':\n",
        "        labels_list_test[i] = 'Player exchange Blue'\n",
        "    elif item == 'pushing-free-kick-red':\n",
        "        labels_list_test[i] = 'Pushing Free-kick Red'\n",
        "    elif item == 'pushing-free-kick-blue':\n",
        "        labels_list_test[i] = 'Pushing Free-kick Blue'\n",
        "    elif item == 'full-time':\n",
        "        labels_list_test[i] = 'Fulltime'\n",
        "\n",
        "# define label_mapping once based on first dataset!!! important :)\n",
        "label_mapping = {label: i for i, label in enumerate(set(labels_list_test))}\n",
        "\n",
        "#reshape data\n",
        "reshaped_data_test = reshape_data(pose_keypoints_test)\n",
        "numerical_labels_test = np.array([label_mapping[label] for label in labels_list_test])\n",
        "\n",
        "X_test = tf.convert_to_tensor(reshaped_data_test, dtype=tf.float32)\n",
        "y_test = tf.keras.utils.to_categorical(numerical_labels_test)\n",
        "\n",
        "#\n",
        "indices = np.random.permutation(len(X_test))\n",
        "indices_tensor = tf.convert_to_tensor(indices, dtype=tf.int32)\n",
        "X_test = tf.gather(X_test, indices_tensor)\n",
        "y_test = tf.gather(y_test, indices_tensor)\n",
        "\n",
        "class_counts = tf.math.reduce_sum(y_test, axis=0)\n",
        "\n",
        "# Print the number of datapoints per class\n",
        "for i, count in enumerate(class_counts):\n",
        "    print(f\"Class {i}: {count}\")"
      ],
      "metadata": {
        "id": "nPtpYc7PhIP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load training data:\n",
        "labels_list_1 = np.load('/content/drive/MyDrive/ModelFiles/labels_list_thunder_new.npy', allow_pickle=True)\n",
        "pose_keypoints_list_1 = np.load('/content/drive/MyDrive/ModelFiles/pose_keypoints_list_thunder_new.npy', allow_pickle=True)\n",
        "\n",
        "for i, item in enumerate(labels_list_1):\n",
        "    if item == 'corner-kick-red':\n",
        "        labels_list_1[i] = 'Corner-kick Red'\n",
        "    elif item == 'corner-kick-blue':\n",
        "        labels_list_1[i] = 'Corner-kick Blue'\n",
        "    elif item == 'goal-red':\n",
        "        labels_list_1[i] = 'Goal Red'\n",
        "    elif item == 'goal-blue':\n",
        "        labels_list_1[i] = 'Goal Blue'\n",
        "    elif item == 'goal-kick-red':\n",
        "        labels_list_1[i] = 'Goal-kick Red'\n",
        "    elif item == 'goal-kick-blue':\n",
        "        labels_list_1[i] = 'Goal-kick Blue'\n",
        "    elif item == 'kick-in-red':\n",
        "        labels_list_1[i] = 'Kick-in Red'\n",
        "    elif item == 'kick-in-blue':\n",
        "        labels_list_1[i] = 'Kick-in Blue'\n",
        "    elif item == 'player-exchange-red':\n",
        "        labels_list_1[i] = 'Player exchange Red'\n",
        "    elif item == 'player-exchange-blue':\n",
        "        labels_list_1[i] = 'Player exchange Blue'\n",
        "    elif item == 'pushing-free-kick-red':\n",
        "        labels_list_1[i] = 'Pushing Free-kick Red'\n",
        "    elif item == 'pushing-free-kick-blue':\n",
        "        labels_list_1[i] = 'Pushing Free-kick Blue'\n",
        "    elif item == 'full-time':\n",
        "        labels_list_1[i] = 'Fulltime'\n",
        "\n",
        "labels_list_2 = np.load('/content/drive/MyDrive/ModelFiles/labels_list_thunder_joey.npy', allow_pickle=True)\n",
        "pose_keypoints_list_2 = np.load('/content/drive/MyDrive/ModelFiles/pose_keypoints_list_thunder_joey.npy', allow_pickle=True)\n",
        "for i, item in enumerate(labels_list_2):\n",
        "    if item == 'Goal_Blue':\n",
        "        labels_list_2[i] = 'Goal Blue'\n",
        "    elif item == 'Goal_Red':\n",
        "      labels_list_2[i] = 'Goal Red'\n",
        "    elif item == 'Kick_In_Blue':\n",
        "      labels_list_2[i] = 'Kick-in Blue'\n",
        "    elif item == 'Kick_In_Red':\n",
        "      labels_list_2[i] = 'Kick-in Red'\n",
        "    elif item == 'Pushing_Free_Kick_Blue':\n",
        "      labels_list_2[i] = 'Pushing Free-kick Blue'\n",
        "    elif item == 'Pushing_Free_Kick_Red':\n",
        "      labels_list_2[i] = 'Pushing Free-kick Red'\n",
        "    elif item == 'Goal_Kick_Red':\n",
        "      labels_list_2[i] = 'Goal-kick Red'\n",
        "    elif item == 'Goal_Kick_Blue':\n",
        "      labels_list_2[i] = 'Goal-kick Blue'\n",
        "    elif item == 'Corner_Kick_Red':\n",
        "      labels_list_2[i] = 'Corner-kick Red'\n",
        "    elif item == 'Corner_Kick_Blue':\n",
        "      labels_list_2[i] = 'Corner-kick Blue'\n",
        "    elif item == 'Player_Exchange_Red':\n",
        "      labels_list_2[i] = 'Player exchange Red'\n",
        "    elif item == 'Player_Exchange_Blue':\n",
        "      labels_list_2[i] = 'Player exchange Blue'\n",
        "    elif item == 'Full_Time_mcp':\n",
        "      labels_list_2[i] = 'Fulltime'\n",
        "\n",
        "# Create a combined array of labels and keypoints\n",
        "combined_data = list(zip(labels_list_2, pose_keypoints_list_2))\n",
        "\n",
        "# Shuffle the combined array\n",
        "np.random.shuffle(combined_data)\n",
        "\n",
        "# Extract the shuffled labels and keypoints\n",
        "labels_list_2, pose_keypoints_list_2 = zip(*combined_data)\n",
        "\n",
        "labels_list_2 = list(labels_list_2)\n",
        "pose_keypoints_list_2 = list(pose_keypoints_list_2 )\n",
        "\n",
        "# Get a certain number of data points\n",
        "num_data_points = 250  # Replace with your desired number\n",
        "labels_list_2 = labels_list_2[:num_data_points]\n",
        "pose_keypoints_list_2 = pose_keypoints_list_2[:num_data_points]\n",
        "\n",
        "\n",
        "#pose_keypoints_list_3 = np.load('/content/drive/MyDrive/ModelFiles/augmented_skeleton_keypoints_500.npy', allow_pickle=True)\n",
        "#labels_list_3 = np.load('/content/drive/MyDrive/ModelFiles/augmented_labels_500.npy', allow_pickle=True)\n",
        "\n",
        "pose_keypoints_list_nao = np.load('/content/drive/MyDrive/ModelFiles/pose_keypoints_list_thunder_test.npy', allow_pickle=True)\n",
        "labels_list_nao = np.load('/content/drive/MyDrive/ModelFiles/labels_list_thunder_test.npy', allow_pickle=True)\n",
        "\n",
        "for i, item in enumerate(labels_list_nao):\n",
        "    if item == 'corner-kick-red':\n",
        "        labels_list_nao[i] = 'Corner-kick Red'\n",
        "    elif item == 'corner-kick-blue':\n",
        "        labels_list_nao[i] = 'Corner-kick Blue'\n",
        "    elif item == 'goal-red':\n",
        "        labels_list_nao[i] = 'Goal Red'\n",
        "    elif item == 'goal-blue':\n",
        "        labels_list_nao[i] = 'Goal Blue'\n",
        "    elif item == 'goal-kick-red':\n",
        "        labels_list_nao[i] = 'Goal-kick Red'\n",
        "    elif item == 'goal-kick-blue':\n",
        "        labels_list_nao[i] = 'Goal-kick Blue'\n",
        "    elif item == 'kick-in-red':\n",
        "        labels_list_nao[i] = 'Kick-in Red'\n",
        "    elif item == 'kick-in-blue':\n",
        "        labels_list_nao[i] = 'Kick-in Blue'\n",
        "    elif item == 'player-exchange-red':\n",
        "        labels_list_nao[i] = 'Player exchange Red'\n",
        "    elif item == 'player-exchange-blue':\n",
        "        labels_list_nao[i] = 'Player exchange Blue'\n",
        "    elif item == 'pushing-free-kick-red':\n",
        "        labels_list_nao[i] = 'Pushing Free-kick Red'\n",
        "    elif item == 'pushing-free-kick-blue':\n",
        "        labels_list_nao[i] = 'Pushing Free-kick Blue'\n",
        "    elif item == 'full-time':\n",
        "        labels_list_nao[i] = 'Fulltime'\n",
        "\n",
        "\n",
        "pose_keypoints_list_5 = np.load('/content/drive/MyDrive/ModelFiles/padding/pose_keypoints_list_thunder_files_pad.npy')\n",
        "labels_list_5 = np.load('/content/drive/MyDrive/ModelFiles/padding/labels_list_thunder_files_pad.npy')\n",
        "\n",
        "\n",
        "pose_keypoints_list_6 = np.load('/content/drive/MyDrive/ModelFiles/padding/pose_keypoints_list_thunder_Newflip.npy')\n",
        "labels_list_6 = np.load('/content/drive/MyDrive/ModelFiles/padding/labels_list_thunder_Newflip.npy')\n",
        "#pose_keypoints_list_4 = np.load('/content/drive/MyDrive/ModelFiles/augmented_skeleton_keypoints_500.npy', allow_pickle=True)\n",
        "#labels_list_4 = np.load('/content/drive/MyDrive/ModelFiles/augmented_labels_500.npy', allow_pickle=True)\n",
        "\n",
        "#pose_keypoints_list_7 = np.load('/content/drive/MyDrive/ModelFiles/augmented_skeleton_keypoints_500_02tr.npy', allow_pickle=True)\n",
        "#labels_list_7 = np.load('/content/drive/MyDrive/ModelFiles/augmented_labels_500_02tr.npy', allow_pickle=True)\n",
        "\n",
        "\n",
        "pose_keypoints_list_8 = np.load('/content/drive/MyDrive/ModelFiles/padding/pose_keypoints_list_thunder_nao2_pad.npy')\n",
        "labels_list_8 = np.load('/content/drive/MyDrive/ModelFiles/padding/labels_list_thunder_nao2_pad.npy')\n",
        "\n",
        "for i, item in enumerate(labels_list_8):\n",
        "    if item == 'corner-kick-red':\n",
        "        labels_list_8[i] = 'Corner-kick Red'\n",
        "    elif item == 'corner-kick-blue':\n",
        "        labels_list_8[i] = 'Corner-kick Blue'\n",
        "    elif item == 'goal-red':\n",
        "        labels_list_8[i] = 'Goal Red'\n",
        "    elif item == 'goal-blue':\n",
        "        labels_list_8[i] = 'Goal Blue'\n",
        "    elif item == 'goal-kick-red':\n",
        "        labels_list_8[i] = 'Goal-kick Red'\n",
        "    elif item == 'goal-kick-blue':\n",
        "        labels_list_8[i] = 'Goal-kick Blue'\n",
        "    elif item == 'kick-in-red':\n",
        "        labels_list_8[i] = 'Kick-in Red'\n",
        "    elif item == 'kick-in-blue':\n",
        "        labels_list_8[i] = 'Kick-in Blue'\n",
        "    elif item == 'player-exchange-red':\n",
        "        labels_list_8[i] = 'Player exchange Red'\n",
        "    elif item == 'player-exchange-blue':\n",
        "        labels_list_8[i] = 'Player exchange Blue'\n",
        "    elif item == 'pushing-free-kick-red':\n",
        "        labels_list_8[i] = 'Pushing Free-kick Red'\n",
        "    elif item == 'pushing-free-kick-blue':\n",
        "        labels_list_8[i] = 'Pushing Free-kick Blue'\n",
        "    elif item == 'full-time':\n",
        "        labels_list_8[i] = 'Fulltime'\n",
        "\n",
        "\n",
        "dataset_vars = [\n",
        "    [pose_keypoints_list_5,\n",
        "     labels_list_5],\n",
        "    [pose_keypoints_list_6,\n",
        "     labels_list_6]\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "split_amount = 0.8\n",
        "X_train, X_val, y_train, y_val = preprocess_datasets(dataset_vars, split_amount)\n",
        "\n",
        "class_counts = tf.math.reduce_sum(y_train, axis=0)\n",
        "for i, count in enumerate(class_counts):\n",
        "    print(f\"Class {i}: {count}\")\n",
        "\n",
        "\n",
        "class_counts = tf.math.reduce_sum(y_val, axis=0)\n",
        "\n",
        "# Print the number of datapoints per class\n",
        "for i, count in enumerate(class_counts):\n",
        "    print(f\"Class {i}: {count}\")\n",
        "\n",
        "\n",
        "\n",
        "print(X_train)\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "lnk6jU9khBYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64, input_shape=(24,18), return_sequences=True))\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=len(label_mapping), activation='softmax'))\n",
        "\n",
        "# Define the initial learning rate and the function to update it\n",
        "initial_learning_rate = 0.5\n",
        "\n",
        "def learning_rate_scheduler(epoch, learning_rate):\n",
        "    factor = 1\n",
        "    if epoch == 100 * factor:  # Adjust this epoch threshold as per your needs\n",
        "        factor += 1\n",
        "        return learning_rate * 0.8  # Reduce the learning rate\n",
        "    return learning_rate\n",
        "\n",
        "# Compile the model with initial learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(lr=initial_learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(learning_rate_scheduler)\n",
        "\n",
        "# Fit the model with the learning rate scheduler callback\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=1024, callbacks=[lr_scheduler])\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(\"Validation loss:\", loss)\n",
        "print(\"Validation accuracy:\", accuracy)\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z97u-QYShSto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eval on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Plot the confusion matrix with accuracy\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_mapping, yticklabels=label_mapping)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy:.2f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J56rRG8AhiAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}